!pip install catboost

import numpy as np
import matplotlib.pyplot as plt
import lightgbm as lgb
from catboost import CatBoostClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import (
    accuracy_score, f1_score, classification_report, confusion_matrix
)

import pandas as pd
# ë°ì´í„° ë¡œë“œ (íŒŒì¼ ê²½ë¡œ/ì´ë¦„ì— ë§ê²Œ ìˆ˜ì •)
A = pd.read_csv('/content/drive/MyDrive/á„á…¢á†¸á„‰á…³á„á…©á†«/2023_á„á…©á†¼á„’á…¡á†¸á„‡á…©á†«(á„†á…®á†«á„á…¦á„‡á…®+á„‡á…µá†¨á„á…¡á„‹á…µá†«á„Œá…³_á„‚á…¦á„‹á…µá„‡á…¥api).csv')  # 2023ë…„ë„ ë°ì´í„°
B = pd.read_csv('/content/drive/MyDrive/á„á…¢á†¸á„‰á…³á„á…©á†«/2024_á„á…©á†¼á„’á…¡á†¸á„‡á…©á†«(á„†á…®á†«á„á…¦á„‡á…®+á„‡á…µá†¨á„á…¡á„‹á…µá†«á„Œá…³+á„‚á…¦á„‹á…µá„‡á…¥api).csv')  # 2024ë…„ë„ ë°ì´í„°

# A, Bì˜ ID ì»¬ëŸ¼ëª…ì´ ë‹¤ë¥´ë¯€ë¡œ í†µì¼ (í•„ìš”ì‹œ)
if 'ì¶•ì œID' in A.columns and 'ì¶•ì œëª… ID' in B.columns:
    B.rename(columns={'ì¶•ì œëª… ID': 'ì¶•ì œID'}, inplace=True)

# === 1. ì‚¬ìš© Feature ë° ë°ì´í„° ë¶„ë¦¬ ===
features = [
    'êµ­ë¹„', 'ì§€ë°©ë¹„', 'ê¸°íƒ€', 'í•©ê³„',
    'ë‚´êµ­ì¸(ëª…)', 'ì™¸êµ­ì¸(ëª…)',
    'G101', 'G201', 'G202', 'G301', 'G401', 'G501',
    'ê°ì„±_ì ìˆ˜í‰ê· ', 'í¬ìŠ¤íŒ…_ë¹ˆë„', 'ê¸ì •_í‚¤ì›Œë“œìˆ˜', 'ë¶€ì •_í‚¤ì›Œë“œìˆ˜',
    'ê¸ì •ë¬¸ì¥ë¹„ìœ¨', 'ì¤‘ë¦½ë¬¸ì¥ë¹„ìœ¨', 'ë¶€ì •ë¬¸ì¥ë¹„ìœ¨'
]

X_train = A[features]
y_train = A['target']  # 0: ì‹¤íŒ¨, 1: ì„±ê³µ

X_test = B[features]
y_test = B['target']

# === 2. NaN ì œê±° ===
mask_test = ~y_test.isna()
X_test_clean = X_test[mask_test]
y_test_clean = y_test[mask_test]

# 1. NaN ì œê±° (ë”± 1ê°œ ìˆëŠ” NaNì„ ì œê±°)
train_mask = ~y_train.isna()
X_train_clean = X_train[train_mask]
y_train_clean = y_train[train_mask]

# 2. LightGBM ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ (ì—¬ê¸°ì„œ clean ë°ì´í„°ë§Œ ì‚¬ìš©í•´ì•¼ í•¨!!)
grid_lgb.fit(X_train_clean, y_train_clean)  # âœ… ë°˜ë“œì‹œ clean ë²„ì „ ì‚¬ìš©

print("NaN in y_train:", y_train.isna().sum())

# === 3. LightGBM ë¶„ë¥˜ ëª¨ë¸ íŠœë‹ ===
lgb_clf = lgb.LGBMClassifier(random_state=42)

param_grid_lgb = {
    'num_leaves': [31, 50],
    'learning_rate': [0.05, 0.1],
    'n_estimators': [100, 200]
}

grid_lgb = GridSearchCV(
    estimator=lgb_clf,
    param_grid=param_grid_lgb,
    scoring='f1',  # ë˜ëŠ” 'accuracy'
    cv=3,
    n_jobs=-1,
    verbose=1
)

grid_lgb.fit(X_train_clean, y_train_clean)  # âœ… NaN ì œê±°ëœ ë³€ìˆ˜ ì‚¬ìš©
print("LightGBM ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°:", grid_lgb.best_params_)

from catboost import CatBoostClassifier
from sklearn.model_selection import GridSearchCV

# 1. CatBoost ë¶„ë¥˜ê¸° ê¸°ë³¸ ëª¨ë¸ ìƒì„±
cat = CatBoostClassifier(random_seed=42, verbose=0)

# 2. í•˜ì´í¼íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ ì„¤ì •
param_grid_cat = {
    'depth': [4, 6, 8],
    'learning_rate': [0.01, 0.05, 0.1],
    'iterations': [100, 200]
}

# 3. GridSearchCV ì„¤ì • (f1 ì ìˆ˜ë¡œ í‰ê°€)
grid_cat = GridSearchCV(
    estimator=cat,
    param_grid=param_grid_cat,
    scoring='f1',
    cv=3,
    n_jobs=-1,
    verbose=1
)

# 4. NaN ì œê±°í•œ ë°ì´í„°ë¡œ í•™ìŠµ
grid_cat.fit(X_train_clean, y_train_clean)

# 5. ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¶œë ¥
print("CatBoost ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°:", grid_cat.best_params_)

# 6. ìµœì  ëª¨ë¸ ì €ì¥
cat_best_model = grid_cat.best_estimator_

# === 5. ìµœì  ëª¨ë¸ë¡œ ì˜ˆì¸¡ ===
lgb_best_model = grid_lgb.best_estimator_
cat_best_model = grid_cat.best_estimator_

lgb_pred_prob = lgb_best_model.predict_proba(X_test_clean)[:, 1]
cat_pred_prob = cat_best_model.predict_proba(X_test_clean)[:, 1]

# í™•ë¥  â†’ í´ë˜ìŠ¤(0 ë˜ëŠ” 1)
lgb_pred = (lgb_pred_prob >= 0.5).astype(int)
cat_pred = (cat_pred_prob >= 0.5).astype(int)

# === 6. í‰ê°€ í•¨ìˆ˜ ===
def print_classification_metrics(y_true, y_pred, model_name):
    acc = accuracy_score(y_true, y_pred)
    f1 = f1_score(y_true, y_pred)
    print(f"\nğŸ“Š {model_name} ì„±ëŠ¥:")
    print(f"  Accuracy: {acc:.4f}")
    print(f"  F1 Score: {f1:.4f}")
    print("  Classification Report:")
    print(classification_report(y_true, y_pred))
    print("  Confusion Matrix:")
    print(confusion_matrix(y_true, y_pred))

print_classification_metrics(y_test_clean, lgb_pred, "LightGBM")
print_classification_metrics(y_test_clean, cat_pred, "CatBoost")