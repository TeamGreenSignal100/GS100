import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.inspection import PartialDependenceDisplay
from xgboost import XGBClassifier
from google.colab import drive
import matplotlib

# í•œê¸€ ê¹¨ì§ ë°©ì§€
!apt-get update -qq
!apt-get install fonts-nanum* -qq
matplotlib.rcParams['font.family'] = 'NanumGothic'
matplotlib.rcParams['axes.unicode_minus'] = False

drive.mount('/content/drive')

# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
file_path_2023 = '/content/drive/MyDrive/ì¶•ì œíŒŒì¼/2023_ë¬¸ì²´ë¶€+ë¹…ì¹´ì¸ì¦ˆ+ë„¤ì´ë²„api.csv'
file_path_2024 = '/content/drive/MyDrive/ì¶•ì œíŒŒì¼/2024_ë¬¸ì²´ë¶€+ë¹…ì¹´ì¸ì¦ˆ+ë„¤ì´ë²„api.csv'

df_2023 = pd.read_csv(file_path_2023)
df_2024 = pd.read_csv(file_path_2024)

# ê²°ì¸¡ì¹˜ ì²˜ë¦¬
def handle_missing_values(df):
    df_cleaned = df[df.isnull().sum(axis=1) <= 1]
    return df_cleaned.fillna(0)

df_2023 = handle_missing_values(df_2023)
df_2024 = handle_missing_values(df_2024)

features = [
    'êµ­ë¹„', 'ì§€ë°©ë¹„', 'ê¸°íƒ€', 'í•©ê³„', 'ë‚´êµ­ì¸(ëª…)', 'ì™¸êµ­ì¸(ëª…)',
    'ê°ì„±_ì ìˆ˜í‰ê· ', 'G101', 'G201', 'G202', 'G301', 'G401', 'G501',
    'í¬ìŠ¤íŒ…_ë¹ˆë„', 'ê¸ì •_í‚¤ì›Œë“œìˆ˜', 'ë¶€ì •_í‚¤ì›Œë“œìˆ˜',
    'ê¸ì •ë¬¸ì¥ë¹„ìœ¨', 'ì¤‘ë¦½ë¬¸ì¥ë¹„ìœ¨', 'ë¶€ì •ë¬¸ì¥ë¹„ìœ¨'
]
target = 'target'

X_train = df_2023[features]
y_train = df_2023[target]
X_test = df_2024[features]
y_test = df_2024[target]

# ìŠ¤ì¼€ì¼ë§ (DataFrame í˜•íƒœ ìœ ì§€)
scaler = StandardScaler()
X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=features)
X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=features)

# XGBoost í•™ìŠµ
xgb_model = XGBClassifier(
    n_estimators=200,
    learning_rate=0.05,
    max_depth=5,
    subsample=0.8,
    colsample_bytree=0.8,
    random_state=42,
    eval_metric='logloss'
)
xgb_model.fit(X_train_scaled, y_train)

# ìƒìœ„ ì¤‘ìš” í”¼ì²˜ ìë™ ì„ íƒ
importances = pd.Series(xgb_model.feature_importances_, index=features)
top_features = importances.sort_values(ascending=False).head(4).index.tolist()
print("ìƒìœ„ ì¤‘ìš” í”¼ì²˜:", top_features)

# subplot ì„¤ì •
n_features = len(top_features)
fig, axes = plt.subplots(n_features, 2, figsize=(14, 4 * n_features))
fig.tight_layout(pad=5)

# í•™ìŠµ ë°ì´í„° ê¸°ì¤€ PDP + ICE
for i, feature in enumerate(top_features):
    PartialDependenceDisplay.from_estimator(
        xgb_model,
        X_train_scaled,
        features=[feature],
        kind='both',          # PDP + ICE
        subsample=50,         # ICE ì¼ë¶€ ìƒ˜í”Œë§Œ í‘œì‹œ
        ax=axes[i, 0]
    )
    axes[i, 0].set_title(f"í•™ìŠµ ë°ì´í„° - {feature}", fontsize=14)

# í…ŒìŠ¤íŠ¸ ë°ì´í„° ê¸°ì¤€ PDP + ICE
for i, feature in enumerate(top_features):
    PartialDependenceDisplay.from_estimator(
        xgb_model,
        X_test_scaled,
        features=[feature],
        kind='both',
        subsample=50,
        ax=axes[i, 1]
    )
    axes[i, 1].set_title(f"í…ŒìŠ¤íŠ¸ ë°ì´í„° - {feature}", fontsize=14)

plt.show()

#--------------------------------

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.inspection import PartialDependenceDisplay
from xgboost import XGBClassifier
from google.colab import drive
import matplotlib
import matplotlib.font_manager as fm

# 1ï¸âƒ£ í•œê¸€ ê¹¨ì§ ë°©ì§€ (Colabìš©)
!apt-get update -qq
!apt-get install fonts-nanum* -qq

# ë‚˜ëˆ”ê³ ë”• í°íŠ¸ ê²½ë¡œ ì§€ì •
nanum_path = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'
fontprop = fm.FontProperties(fname=nanum_path)

plt.rcParams['font.family'] = fontprop.get_name()
plt.rcParams['axes.unicode_minus'] = False

# 2ï¸âƒ£ Google Drive ë§ˆìš´íŠ¸
drive.mount('/content/drive')

# 3ï¸âƒ£ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
file_path_2023 = '/content/drive/MyDrive/ì¶•ì œíŒŒì¼/2023_ë¬¸ì²´ë¶€+ë¹…ì¹´ì¸ì¦ˆ+ë„¤ì´ë²„api.csv'
file_path_2024 = '/content/drive/MyDrive/ì¶•ì œíŒŒì¼/2024_ë¬¸ì²´ë¶€+ë¹…ì¹´ì¸ì¦ˆ+ë„¤ì´ë²„api.csv'

df_2023 = pd.read_csv(file_path_2023)
df_2024 = pd.read_csv(file_path_2024)

# 4ï¸âƒ£ ê²°ì¸¡ì¹˜ ì²˜ë¦¬
def handle_missing_values(df):
    df_cleaned = df[df.isnull().sum(axis=1) <= 1]
    return df_cleaned.fillna(0)

df_2023 = handle_missing_values(df_2023)
df_2024 = handle_missing_values(df_2024)

features = [
    'êµ­ë¹„', 'ì§€ë°©ë¹„', 'ê¸°íƒ€', 'í•©ê³„', 'ë‚´êµ­ì¸(ëª…)', 'ì™¸êµ­ì¸(ëª…)',
    'ê°ì„±_ì ìˆ˜í‰ê· ', 'G101', 'G201', 'G202', 'G301', 'G401', 'G501',
    'í¬ìŠ¤íŒ…_ë¹ˆë„', 'ê¸ì •_í‚¤ì›Œë“œìˆ˜', 'ë¶€ì •_í‚¤ì›Œë“œìˆ˜',
    'ê¸ì •ë¬¸ì¥ë¹„ìœ¨', 'ì¤‘ë¦½ë¬¸ì¥ë¹„ìœ¨', 'ë¶€ì •ë¬¸ì¥ë¹„ìœ¨'
]
target = 'target'

X_train = df_2023[features]
y_train = df_2023[target]
X_test = df_2024[features]
y_test = df_2024[target]

# 5ï¸âƒ£ ìŠ¤ì¼€ì¼ë§
scaler = StandardScaler()
X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=features)
X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=features)

# 6ï¸âƒ£ XGBoost í•™ìŠµ
xgb_model = XGBClassifier(
    n_estimators=200,
    learning_rate=0.05,
    max_depth=5,
    subsample=0.8,
    colsample_bytree=0.8,
    random_state=42,
    eval_metric='logloss'
)
xgb_model.fit(X_train_scaled, y_train)

# 7ï¸âƒ£ ìƒìœ„ ì¤‘ìš” í”¼ì²˜ ì„ íƒ
importances = pd.Series(xgb_model.feature_importances_, index=features)
top_features = importances.sort_values(ascending=False).head(8).index.tolist()
print("ìƒìœ„ ì¤‘ìš” í”¼ì²˜:", top_features)

# 8ï¸âƒ£ subplot ì„¤ì •
n_features = len(top_features)
fig, axes = plt.subplots(n_features, 2, figsize=(16, 4 * n_features))
fig.tight_layout(pad=5)

# ìƒ‰ìƒ ì„¤ì •
pdp_color = 'red'       # PDP ê°•ì¡° ìƒ‰
ice_color = 'gray'      # ICE ì–‡ì€ ì„  ìƒ‰

# 9ï¸âƒ£ PDP + ICE í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë°ì´í„° ì‹œê°í™” í•¨ìˆ˜
def plot_pdp_ice(ax, X, feature, dataset_name):
    disp = PartialDependenceDisplay.from_estimator(
        xgb_model,
        X,
        features=[feature],
        kind='both',
        subsample=50,
        ax=ax
    )
    ax.set_title(f"{dataset_name} - {feature}", fontsize=14, fontproperties=fontprop)
    ax.set_xlabel("íŠ¹ì„± ê°’", fontsize=12, fontproperties=fontprop)
    ax.set_ylabel("ì˜ˆì¸¡ í™•ë¥ ", fontsize=12, fontproperties=fontprop)

    # legend ì œê±°
    ax.legend().remove()

    # ì„  êµµê¸°/ìƒ‰ìƒ ì¡°ì •
    lines = ax.get_lines()
    for j, line in enumerate(lines):
        if j == 0:  # PDP
            line.set_linewidth(3)
            line.set_color(pdp_color)
        else:       # ICE
            line.set_linewidth(0.8)
            line.set_color(ice_color)

    # legend ìƒˆë¡œ ìƒì„±
    labels = [f'PDP: {feature}'] + [f'ICE {j+1}' for j in range(len(lines)-1)]
    for line, label in zip(lines, labels):
        line.set_label(label)
    ax.legend(frameon=False, fontsize=10)

# 10ï¸âƒ£ í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë°ì´í„° ê·¸ë¦¬ê¸°
for i, feature in enumerate(top_features):
    plot_pdp_ice(axes[i, 0], X_train_scaled, feature, "í•™ìŠµ ë°ì´í„°")
    plot_pdp_ice(axes[i, 1], X_test_scaled, feature, "í…ŒìŠ¤íŠ¸ ë°ì´í„°")

plt.show()


#---------------------------

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.inspection import PartialDependenceDisplay
from xgboost import XGBClassifier
from google.colab import drive
import matplotlib
import matplotlib.font_manager as fm

# 1ï¸âƒ£ í•œê¸€ ê¹¨ì§ ë°©ì§€ (Colabìš©)
!apt-get update -qq
!apt-get install fonts-nanum* -qq

# ë‚˜ëˆ”ê³ ë”• í°íŠ¸ ê²½ë¡œ ì§€ì •
nanum_path = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'
fontprop = fm.FontProperties(fname=nanum_path)

plt.rcParams['font.family'] = fontprop.get_name()
plt.rcParams['axes.unicode_minus'] = False

# 2ï¸âƒ£ Google Drive ë§ˆìš´íŠ¸
drive.mount('/content/drive')

# 3ï¸âƒ£ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
file_path_2023 = '/content/drive/MyDrive/ì¶•ì œíŒŒì¼/2023_ë¬¸ì²´ë¶€+ë¹…ì¹´ì¸ì¦ˆ+ë„¤ì´ë²„api.csv'
file_path_2024 = '/content/drive/MyDrive/ì¶•ì œíŒŒì¼/2024_ë¬¸ì²´ë¶€+ë¹…ì¹´ì¸ì¦ˆ+ë„¤ì´ë²„api.csv'

df_2023 = pd.read_csv(file_path_2023)
df_2024 = pd.read_csv(file_path_2024)

# 4ï¸âƒ£ ê²°ì¸¡ì¹˜ ì²˜ë¦¬
def handle_missing_values(df):
    df_cleaned = df[df.isnull().sum(axis=1) <= 1]
    return df_cleaned.fillna(0)

df_2023 = handle_missing_values(df_2023)
df_2024 = handle_missing_values(df_2024)

# 5ï¸âƒ£ í•œê¸€ â†’ ì˜ì–´ ì»¬ëŸ¼ ë§¤í•‘
col_mapping = {
    'êµ­ë¹„': 'national_budget',
    'ì§€ë°©ë¹„': 'local_budget',
    'ê¸°íƒ€': 'other_budget',
    'í•©ê³„': 'total_budget',
    'ë‚´êµ­ì¸(ëª…)': 'domestic_visitors',
    'ì™¸êµ­ì¸(ëª…)': 'foreign_visitors',
    'ê°ì„±_ì ìˆ˜í‰ê· ': 'sentiment_avg',
    'G101': 'G101',
    'G201': 'G201',
    'G202': 'G202',
    'G301': 'G301',
    'G401': 'G401',
    'G501': 'G501',
    'í¬ìŠ¤íŒ…_ë¹ˆë„': 'posting_freq',
    'ê¸ì •_í‚¤ì›Œë“œìˆ˜': 'positive_keywords',
    'ë¶€ì •_í‚¤ì›Œë“œìˆ˜': 'negative_keywords',
    'ê¸ì •ë¬¸ì¥ë¹„ìœ¨': 'positive_ratio',
    'ì¤‘ë¦½ë¬¸ì¥ë¹„ìœ¨': 'neutral_ratio',
    'ë¶€ì •ë¬¸ì¥ë¹„ìœ¨': 'negative_ratio',
    'target': 'target'
}

df_2023.rename(columns=col_mapping, inplace=True)
df_2024.rename(columns=col_mapping, inplace=True)

# 6ï¸âƒ£ features, target ì •ì˜
features = [
    'national_budget', 'local_budget', 'other_budget', 'total_budget',
    'domestic_visitors', 'foreign_visitors', 'sentiment_avg',
    'G101', 'G201', 'G202', 'G301', 'G401', 'G501',
    'posting_freq', 'positive_keywords', 'negative_keywords',
    'positive_ratio', 'neutral_ratio', 'negative_ratio'
]
target = 'target'

X_train = df_2023[features]
y_train = df_2023[target]
X_test = df_2024[features]
y_test = df_2024[target]

# 7ï¸âƒ£ ìŠ¤ì¼€ì¼ë§
scaler = StandardScaler()
X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=features)
X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=features)

# 8ï¸âƒ£ XGBoost í•™ìŠµ
xgb_model = XGBClassifier(
    n_estimators=200,
    learning_rate=0.05,
    max_depth=5,
    subsample=0.8,
    colsample_bytree=0.8,
    random_state=42,
    eval_metric='logloss'
)
xgb_model.fit(X_train_scaled, y_train)

# 9ï¸âƒ£ ìƒìœ„ ì¤‘ìš” í”¼ì²˜ ì„ íƒ
importances = pd.Series(xgb_model.feature_importances_, index=features)
top_features = importances.sort_values(ascending=False).head(8).index.tolist()
print("ìƒìœ„ ì¤‘ìš” í”¼ì²˜:", top_features)

# ğŸ”Ÿ subplot ì„¤ì •
n_features = len(top_features)
fig, axes = plt.subplots(n_features, 2, figsize=(16, 4 * n_features))
fig.tight_layout(pad=5)

# ìƒ‰ìƒ ì„¤ì •
pdp_color = 'red'       # PDP ê°•ì¡° ìƒ‰
ice_color = 'gray'      # ICE ì–‡ì€ ì„  ìƒ‰

# 11ï¸âƒ£ PDP + ICE í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë°ì´í„° ì‹œê°í™” í•¨ìˆ˜
def plot_pdp_ice(ax, X, feature, dataset_name):
    disp = PartialDependenceDisplay.from_estimator(
        xgb_model,
        X,
        features=[feature],
        kind='both',
        subsample=50,
        ax=ax
    )
    ax.set_title(f"{dataset_name} - {feature}", fontsize=14, fontproperties=fontprop)
    ax.set_xlabel("íŠ¹ì„± ê°’", fontsize=12, fontproperties=fontprop)
    ax.set_ylabel("ì˜ˆì¸¡ í™•ë¥ ", fontsize=12, fontproperties=fontprop)

    # legend ì œê±°
    ax.legend().remove()

    # ì„  êµµê¸°/ìƒ‰ìƒ ì¡°ì •
    lines = ax.get_lines()
    for j, line in enumerate(lines):
        if j == 0:  # PDP
            line.set_linewidth(3)
            line.set_color(pdp_color)
        else:       # ICE
            line.set_linewidth(0.8)
            line.set_color(ice_color)

    # legend ìƒˆë¡œ ìƒì„±
    labels = [f'PDP: {feature}'] + [f'ICE {j+1}' for j in range(len(lines)-1)]
    for line, label in zip(lines, labels):
        line.set_label(label)
    ax.legend(frameon=False, fontsize=10)

# 12ï¸âƒ£ í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë°ì´í„° ê·¸ë¦¬ê¸°
for i, feature in enumerate(top_features):
    plot_pdp_ice(axes[i, 0], X_train_scaled, feature, "í•™ìŠµ ë°ì´í„°")
    plot_pdp_ice(axes[i, 1], X_test_scaled, feature, "í…ŒìŠ¤íŠ¸ ë°ì´í„°")

plt.show()

#--------------------------------------------------

#ëœë¤ í¬ë ˆìŠ¤íŠ¸
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import RandomizedSearchCV
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    classification_report
)
from sklearn.inspection import PartialDependenceDisplay
from google.colab import drive
import matplotlib.font_manager as fm

# í•œê¸€ í°íŠ¸ ì„¤ì •
!apt-get update -qq
!apt-get install fonts-nanum* -qq
nanum_path = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'
fontprop = fm.FontProperties(fname=nanum_path)
plt.rcParams['font.family'] = fontprop.get_name()
plt.rcParams['axes.unicode_minus'] = False

# Google Drive ë§ˆìš´íŠ¸
drive.mount('/content/drive')

# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
file_path_2023 = '/content/drive/MyDrive/ì¶•ì œíŒŒì¼/2023_ë¬¸ì²´ë¶€+ë¹…ì¹´ì¸ì¦ˆ+ë„¤ì´ë²„api.csv'
file_path_2024 = '/content/drive/MyDrive/ì¶•ì œíŒŒì¼/2024_ë¬¸ì²´ë¶€+ë¹…ì¹´ì¸ì¦ˆ+ë„¤ì´ë²„api.csv'
df_2023 = pd.read_csv(file_path_2023)
df_2024 = pd.read_csv(file_path_2024)

# ê²°ì¸¡ì¹˜ ì²˜ë¦¬
def handle_missing_values(df):
    df_cleaned = df[df.isnull().sum(axis=1) <= 1]
    return df_cleaned.fillna(0)

df_2023 = handle_missing_values(df_2023)
df_2024 = handle_missing_values(df_2024)

# í•œê¸€ â†’ ì˜ì–´ ì»¬ëŸ¼ ë§¤í•‘
col_mapping = {
    'êµ­ë¹„': 'national_budget',
    'ì§€ë°©ë¹„': 'local_budget',
    'ê¸°íƒ€': 'other_budget',
    'í•©ê³„': 'total_budget',
    'ë‚´êµ­ì¸(ëª…)': 'domestic_visitors',
    'ì™¸êµ­ì¸(ëª…)': 'foreign_visitors',
    'ê°ì„±_ì ìˆ˜í‰ê· ': 'sentiment_avg',
    'G101': 'G101',
    'G201': 'G201',
    'G202': 'G202',
    'G301': 'G301',
    'G401': 'G401',
    'G501': 'G501',
    'í¬ìŠ¤íŒ…_ë¹ˆë„': 'posting_freq',
    'ê¸ì •_í‚¤ì›Œë“œìˆ˜': 'positive_keywords',
    'ë¶€ì •_í‚¤ì›Œë“œìˆ˜': 'negative_keywords',
    'ê¸ì •ë¬¸ì¥ë¹„ìœ¨': 'positive_ratio',
    'ì¤‘ë¦½ë¬¸ì¥ë¹„ìœ¨': 'neutral_ratio',
    'ë¶€ì •ë¬¸ì¥ë¹„ìœ¨': 'negative_ratio',
    'target': 'target'
}

# ì»¬ëŸ¼ëª… ë³€í™˜
df_2023.rename(columns=col_mapping, inplace=True)
df_2024.rename(columns=col_mapping, inplace=True)

# features, target ì—…ë°ì´íŠ¸
features = [
    'national_budget', 'local_budget', 'other_budget', 'total_budget',
    'domestic_visitors', 'foreign_visitors', 'sentiment_avg',
    'G101', 'G201', 'G202', 'G301', 'G401', 'G501',
    'posting_freq', 'positive_keywords', 'negative_keywords',
    'positive_ratio', 'neutral_ratio', 'negative_ratio'
]
target = 'target'

X_train, y_train = df_2023[features], df_2023[target]
X_test, y_test = df_2024[features], df_2024[target]

# ìŠ¤ì¼€ì¼ë§
scaler = StandardScaler()
X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=features)
X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=features)

# ëœë¤í¬ë ˆìŠ¤íŠ¸ + RandomizedSearchCV
param_grid = {
    'n_estimators': [100, 300],
    'max_depth': [10, 20],
    'min_samples_split': [2, 5],
    'min_samples_leaf': [1, 2],
    'max_features': ['sqrt'],
    'class_weight': [None]
}

rand_rf = RandomizedSearchCV(
    RandomForestClassifier(random_state=42, n_jobs=-1),
    param_distributions=param_grid,
    n_iter=6,
    cv=3,
    scoring='f1_weighted',
    n_jobs=-1,
    random_state=42
)
rand_rf.fit(X_train_scaled, y_train)
best_rf_model = rand_rf.best_estimator_

y_pred = best_rf_model.predict(X_test_scaled)

print("ìµœì  ëœë¤ í¬ë ˆìŠ¤íŠ¸ ì„±ëŠ¥ (í…ŒìŠ¤íŠ¸ì…‹)")
print("Accuracy:", accuracy_score(y_test, y_pred))
print("Precision:", precision_score(y_test, y_pred, average='weighted'))
print("Recall:", recall_score(y_test, y_pred, average='weighted'))
print("F1 Score:", f1_score(y_test, y_pred, average='weighted'))
print(classification_report(y_test, y_pred))

# ìƒìœ„ ì¤‘ìš” í”¼ì²˜ ì„ ì •
importances_rf = pd.Series(best_rf_model.feature_importances_, index=features)
top_features_rf = importances_rf.sort_values(ascending=False).head(4).index.tolist()

# PDP + ICE ì‹œê°í™”
n_features = len(top_features_rf)
fig, axes = plt.subplots(n_features, 2, figsize=(16, 4 * n_features))
fig.tight_layout(pad=5)

for i, feature in enumerate(top_features_rf):
    # í•™ìŠµ ë°ì´í„° ìƒ˜í”Œë§
    X_train_sample = X_train_scaled.sample(min(100, len(X_train_scaled)), random_state=42)
    disp = PartialDependenceDisplay.from_estimator(
        best_rf_model, X_train_sample, features=[feature], kind='both', ax=axes[i, 0]
    )
    lines = axes[i, 0].get_lines()
    if len(lines) > 0:
        for line in lines[1:]:
            line.set_color('lightgray')
            line.set_linewidth(0.8)
        lines[0].set_color('red')
        lines[0].set_linewidth(2.5)
    axes[i, 0].set_title(f"í•™ìŠµ ë°ì´í„° - {feature}", fontproperties=fontprop)

    X_test_sample = X_test_scaled.sample(min(100, len(X_test_scaled)), random_state=42)
    disp_test = PartialDependenceDisplay.from_estimator(
        best_rf_model, X_test_sample, features=[feature], kind='both', ax=axes[i, 1]
    )
    lines_test = axes[i, 1].get_lines()
    if len(lines_test) > 0:
        for line in lines_test[1:]:
            line.set_color('lightgray')
            line.set_linewidth(0.8)
        lines_test[0].set_color('red')
        lines_test[0].set_linewidth(2.5)
    axes[i, 1].set_title(f"í…ŒìŠ¤íŠ¸ ë°ì´í„° - {feature}", fontproperties=fontprop)

plt.show()

